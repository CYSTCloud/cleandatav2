{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3 : Chargement des Données (Version 2)\n",
    "\n",
    "Ce notebook présente le processus de chargement des données transformées dans notre base de données MySQL pour notre projet ETL sur les pandémies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "import pymysql\n",
    "import warnings\n",
    "\n",
    "# Ignorer les avertissements\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour afficher plus de colonnes\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des données nettoyées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répertoire des données nettoyées\n",
    "clean_data_dir = './donnees_nettoyees/'\n",
    "\n",
    "# Fonction pour charger un fichier CSV avec gestion des erreurs\n",
    "def load_csv_file(file_path, file_desc):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Données {file_desc} chargées avec succès. Forme: {df.shape}\")\n",
    "        display(df.head())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des données {file_desc}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Chargement des fichiers CSV\n",
    "confirmed_df = load_csv_file(os.path.join(clean_data_dir, 'cas_confirmes_clean.csv'), 'de cas confirmés')\n",
    "deaths_df = load_csv_file(os.path.join(clean_data_dir, 'deces_clean.csv'), 'de décès')\n",
    "recovered_df = load_csv_file(os.path.join(clean_data_dir, 'guerisons_clean.csv'), 'de guérisons')\n",
    "locations_df = load_csv_file(os.path.join(clean_data_dir, 'localisations_clean.csv'), 'de localisations')\n",
    "pandemics_df = load_csv_file(os.path.join(clean_data_dir, 'pandemies_clean.csv'), 'de pandémies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Préparation des données pour le chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation de la table des dates (calendrier)\n",
    "def prepare_calendar_table():\n",
    "    # Collecte de toutes les dates uniques\n",
    "    dates = set()\n",
    "    \n",
    "    if confirmed_df is not None and 'date' in confirmed_df.columns:\n",
    "        dates.update(confirmed_df['date'].unique())\n",
    "    \n",
    "    if deaths_df is not None and 'date' in deaths_df.columns:\n",
    "        dates.update(deaths_df['date'].unique())\n",
    "    \n",
    "    if recovered_df is not None and 'date' in recovered_df.columns:\n",
    "        dates.update(recovered_df['date'].unique())\n",
    "    \n",
    "    # Création du DataFrame de calendrier\n",
    "    if dates:\n",
    "        dates = sorted(list(dates))\n",
    "        calendar_df = pd.DataFrame({\n",
    "            'date': dates,\n",
    "        })\n",
    "        \n",
    "        # Conversion en datetime pour extraire les composants\n",
    "        calendar_df['date'] = pd.to_datetime(calendar_df['date'])\n",
    "        \n",
    "        # Ajout de l'ID et des composants de date\n",
    "        calendar_df['id_date'] = range(1, len(calendar_df) + 1)\n",
    "        calendar_df['jour'] = calendar_df['date'].dt.day\n",
    "        calendar_df['mois'] = calendar_df['date'].dt.month\n",
    "        calendar_df['annee'] = calendar_df['date'].dt.year\n",
    "        calendar_df['trimestre'] = calendar_df['date'].dt.quarter\n",
    "        calendar_df['jour_semaine'] = calendar_df['date'].dt.dayofweek + 1  # 1 = Lundi, 7 = Dimanche\n",
    "        \n",
    "        # Conversion de la date en string pour le stockage SQL\n",
    "        calendar_df['date'] = calendar_df['date'].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Réorganisation des colonnes\n",
    "        calendar_df = calendar_df[['id_date', 'date', 'jour', 'mois', 'annee', 'trimestre', 'jour_semaine']]\n",
    "        \n",
    "        return calendar_df\n",
    "    else:\n",
    "        print(\"Aucune date trouvée dans les données.\")\n",
    "        return None\n",
    "\n",
    "# Préparation de la table des données principales\n",
    "def prepare_main_data_table():\n",
    "    # Préparation de la table de données principale\n",
    "    data_records = []\n",
    "    \n",
    "    # Fonction pour ajouter des enregistrements à partir d'un DataFrame\n",
    "    def add_records_from_df(df, value_column, calendar_df, locations_df):\n",
    "        if df is None or calendar_df is None or locations_df is None:\n",
    "            return\n",
    "        \n",
    "        # Création d'un dictionnaire de mapping pour les dates\n",
    "        date_mapping = dict(zip(calendar_df['date'], calendar_df['id_date']))\n",
    "        \n",
    "        # Création d'un dictionnaire de mapping pour les localisations\n",
    "        location_mapping = dict(zip(locations_df['pays'], locations_df['id_localisation']))\n",
    "        \n",
    "        # Parcours des lignes du DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            date_str = pd.to_datetime(row['date']).strftime('%Y-%m-%d') if pd.notna(row['date']) else None\n",
    "            pays = row['pays'] if pd.notna(row['pays']) else None\n",
    "            id_pandemie = row['id_pandemie'] if 'id_pandemie' in row and pd.notna(row['id_pandemie']) else None\n",
    "            value = row[value_column] if pd.notna(row[value_column]) else 0\n",
    "            \n",
    "            if date_str in date_mapping and pays in location_mapping and id_pandemie is not None:\n",
    "                data_records.append({\n",
    "                    'id_date': date_mapping[date_str],\n",
    "                    'id_localisation': location_mapping[pays],\n",
    "                    'id_pandemie': id_pandemie,\n",
    "                    value_column: value\n",
    "                })\n",
    "    \n",
    "    # Préparation du calendrier\n",
    "    calendar_df = prepare_calendar_table()\n",
    "    \n",
    "    # Ajout des enregistrements à partir des différents DataFrames\n",
    "    if confirmed_df is not None and 'cas_confirmes' in confirmed_df.columns:\n",
    "        add_records_from_df(confirmed_df, 'cas_confirmes', calendar_df, locations_df)\n",
    "    \n",
    "    if deaths_df is not None and 'deces' in deaths_df.columns:\n",
    "        add_records_from_df(deaths_df, 'deces', calendar_df, locations_df)\n",
    "    \n",
    "    if recovered_df is not None and 'guerisons' in recovered_df.columns:\n",
    "        add_records_from_df(recovered_df, 'guerisons', calendar_df, locations_df)\n",
    "    \n",
    "    # Création du DataFrame de données\n",
    "    if data_records:\n",
    "        data_df = pd.DataFrame(data_records)\n",
    "        \n",
    "        # Agrégation des données pour éviter les doublons\n",
    "        data_df = data_df.groupby(['id_date', 'id_localisation', 'id_pandemie']).sum().reset_index()\n",
    "        \n",
    "        # Ajout d'un ID unique\n",
    "        data_df['id_data'] = range(1, len(data_df) + 1)\n",
    "        \n",
    "        # Réorganisation des colonnes\n",
    "        columns = ['id_data', 'id_date', 'id_localisation', 'id_pandemie']\n",
    "        value_columns = [col for col in data_df.columns if col not in columns]\n",
    "        data_df = data_df[columns + value_columns]\n",
    "        \n",
    "        return data_df, calendar_df\n",
    "    else:\n",
    "        print(\"Aucune donnée trouvée pour la table principale.\")\n",
    "        return None, calendar_df\n",
    "\n",
    "# Préparation des tables\n",
    "data_df, calendar_df = prepare_main_data_table()\n",
    "\n",
    "# Affichage des tables préparées\n",
    "if calendar_df is not None:\n",
    "    print(f\"Table de calendrier préparée avec {len(calendar_df)} entrées.\")\n",
    "    display(calendar_df.head())\n",
    "\n",
    "if data_df is not None:\n",
    "    print(f\"Table de données principale préparée avec {len(data_df)} entrées.\")\n",
    "    display(data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration de la connexion à la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de connexion à la base de données\n",
    "db_user = 'root'  # Modifiez selon votre configuration\n",
    "db_password = 'votre_mot_de_passe'  # Modifiez selon votre configuration\n",
    "db_host = 'localhost'\n",
    "db_port = '3306'\n",
    "db_name = 'pandemies_db'  # Assurez-vous que cette base de données existe\n",
    "\n",
    "# Chaîne de connexion\n",
    "connection_string = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "# Création du moteur SQLAlchemy\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"Connexion à la base de données établie avec succès.\")\n",
    "    \n",
    "    # Test de connexion\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT 1\"))\n",
    "        print(\"Test de connexion réussi.\")\n",
    "        \n",
    "        # Affichage des tables existantes\n",
    "        tables = engine.table_names()\n",
    "        print(f\"Tables existantes dans la base de données: {tables}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la connexion à la base de données: {e}\")\n",
    "    engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Création du schéma de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du schéma de la base de données\n",
    "def create_database_schema(engine):\n",
    "    if engine is None:\n",
    "        print(\"Impossible de créer le schéma de la base de données sans connexion.\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Création des tables\n",
    "        with engine.connect() as conn:\n",
    "            # Table calendrier\n",
    "            conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS calendrier (\n",
    "                id_date INT PRIMARY KEY,\n",
    "                date DATE NOT NULL,\n",
    "                jour INT NOT NULL,\n",
    "                mois INT NOT NULL,\n",
    "                annee INT NOT NULL,\n",
    "                trimestre INT NOT NULL,\n",
    "                jour_semaine INT NOT NULL\n",
    "            )\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Table localisation\n",
    "            conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS localisation (\n",
    "                id_localisation INT PRIMARY KEY,\n",
    "                pays VARCHAR(100) NOT NULL,\n",
    "                code_pays VARCHAR(3),\n",
    "                region VARCHAR(100),\n",
    "                continent VARCHAR(50),\n",
    "                latitude FLOAT,\n",
    "                longitude FLOAT,\n",
    "                population BIGINT\n",
    "            )\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Table pandemie\n",
    "            conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS pandemie (\n",
    "                id_pandemie INT PRIMARY KEY,\n",
    "                nom VARCHAR(100) NOT NULL,\n",
    "                agent_pathogene VARCHAR(100),\n",
    "                description TEXT,\n",
    "                date_debut DATE,\n",
    "                date_fin DATE\n",
    "            )\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Table data\n",
    "            conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS data (\n",
    "                id_data INT PRIMARY KEY,\n",
    "                id_date INT NOT NULL,\n",
    "                id_localisation INT NOT NULL,\n",
    "                id_pandemie INT NOT NULL,\n",
    "                cas_confirmes INT DEFAULT 0,\n",
    "                deces INT DEFAULT 0,\n",
    "                guerisons INT DEFAULT 0,\n",
    "                FOREIGN KEY (id_date) REFERENCES calendrier(id_date),\n",
    "                FOREIGN KEY (id_localisation) REFERENCES localisation(id_localisation),\n",
    "                FOREIGN KEY (id_pandemie) REFERENCES pandemie(id_pandemie)\n",
    "            )\n",
    "            \"\"\"))\n",
    "            \n",
    "            conn.commit()\n",
    "        \n",
    "        print(\"Schéma de la base de données créé avec succès.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création du schéma de la base de données: {e}\")\n",
    "        return False\n",
    "\n",
    "# Création du schéma\n",
    "schema_created = create_database_schema(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chargement des données dans la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger un DataFrame dans une table\n",
    "def load_table(df, table_name, engine, if_exists='replace'):\n",
    "    if df is None or engine is None:\n",
    "        print(f\"Impossible de charger les données dans la table {table_name}.\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Chargement des données\n",
    "        df.to_sql(table_name, engine, if_exists=if_exists, index=False)\n",
    "        \n",
    "        # Vérification du nombre de lignes chargées\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "            count = result.fetchone()[0]\n",
    "            print(f\"Données chargées avec succès dans la table {table_name}. Nombre de lignes: {count}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des données dans la table {table_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Chargement des tables\n",
    "if schema_created:\n",
    "    # Chargement des tables de dimension\n",
    "    load_table(calendar_df, 'calendrier', engine, 'replace')\n",
    "    load_table(locations_df, 'localisation', engine, 'replace')\n",
    "    load_table(pandemics_df, 'pandemie', engine, 'replace')\n",
    "    \n",
    "    # Chargement de la table de faits\n",
    "    load_table(data_df, 'data', engine, 'replace')\n",
    "else:\n",
    "    print(\"Le chargement des données a été annulé car le schéma n'a pas pu être créé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vérification des données chargées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour exécuter une requête SQL et afficher les résultats\n",
    "def execute_query(query, description, engine):\n",
    "    if engine is None:\n",
    "        print(f\"Impossible d'exécuter la requête: {description}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(query))\n",
    "            df = pd.DataFrame(result.fetchall())\n",
    "            if not df.empty:\n",
    "                df.columns = result.keys()\n",
    "            print(f\"Résultats de la requête: {description}\")\n",
    "            display(df)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exécution de la requête {description}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Vérification des données chargées\n",
    "if engine is not None:\n",
    "    # Nombre de lignes par table\n",
    "    execute_query(\"SELECT 'calendrier' AS table_name, COUNT(*) AS row_count FROM calendrier UNION ALL \\\n",
    "                  SELECT 'localisation', COUNT(*) FROM localisation UNION ALL \\\n",
    "                  SELECT 'pandemie', COUNT(*) FROM pandemie UNION ALL \\\n",
    "                  SELECT 'data', COUNT(*) FROM data\", \n",
    "                  \"Nombre de lignes par table\", engine)\n",
    "    \n",
    "    # Exemple de requête sur les données\n",
    "    execute_query(\"\"\"SELECT p.nom AS pandemie, l.pays, c.date, d.cas_confirmes, d.deces, d.guerisons\n",
    "                    FROM data d\n",
    "                    JOIN calendrier c ON d.id_date = c.id_date\n",
    "                    JOIN localisation l ON d.id_localisation = l.id_localisation\n",
    "                    JOIN pandemie p ON d.id_pandemie = p.id_pandemie\n",
    "                    ORDER BY c.date DESC, l.pays\n",
    "                    LIMIT 10\"\"\", \n",
    "                  \"Exemple de données chargées\", engine)\n",
    "    \n",
    "    # Statistiques par pandémie\n",
    "    execute_query(\"\"\"SELECT p.nom AS pandemie, \n",
    "                        SUM(d.cas_confirmes) AS total_cas, \n",
    "                        SUM(d.deces) AS total_deces, \n",
    "                        SUM(d.guerisons) AS total_guerisons\n",
    "                    FROM data d\n",
    "                    JOIN pandemie p ON d.id_pandemie = p.id_pandemie\n",
    "                    GROUP BY p.nom\"\"\", \n",
    "                  \"Statistiques par pandémie\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Ce notebook a permis de charger les données transformées dans la base de données MySQL. Les étapes suivantes ont été réalisées :\n",
    "\n",
    "1. Chargement des données nettoyées depuis les fichiers CSV\n",
    "2. Préparation des tables pour le chargement\n",
    "3. Configuration de la connexion à la base de données\n",
    "4. Création du schéma de la base de données\n",
    "5. Chargement des données dans les tables\n",
    "6. Vérification des données chargées\n",
    "\n",
    "Le processus ETL est maintenant complet :\n",
    "- **Extraction** : Les données ont été extraites des fichiers CSV et JSON sources\n",
    "- **Transformation** : Les données ont été nettoyées, agrégées, normalisées et les doublons ont été supprimés\n",
    "- **Chargement** : Les données transformées ont été chargées dans la base de données MySQL\n",
    "\n",
    "Les données sont maintenant prêtes pour l'analyse et la visualisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
