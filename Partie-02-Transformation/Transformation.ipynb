{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Transformation des Données\n",
    "\n",
    "Ce notebook présente le processus de transformation des données brutes pour notre projet ETL sur les pandémies. Nous allons nettoyer, agréger, normaliser et supprimer les doublons des données extraites dans la phase précédente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration pour afficher plus de colonnes\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répertoire des données brutes\n",
    "raw_data_dir = './Donnees Brutes/'\n",
    "\n",
    "# Chemins des fichiers de données\n",
    "covid_data_path = os.path.join(raw_data_dir, 'covid_19_clean_complete.csv')\n",
    "monkeypox_data_path = os.path.join(raw_data_dir, 'owid-monkeypox-data.csv')\n",
    "worldometer_data_path = os.path.join(raw_data_dir, 'worldometer_coronavirus_daily_data.csv')\n",
    "\n",
    "# Chargement des données\n",
    "try:\n",
    "    covid_df = pd.read_csv(covid_data_path)\n",
    "    print(f\"Données COVID-19 chargées avec succès. Forme: {covid_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des données COVID-19: {e}\")\n",
    "    covid_df = None\n",
    "\n",
    "try:\n",
    "    monkeypox_df = pd.read_csv(monkeypox_data_path)\n",
    "    print(f\"Données Monkeypox chargées avec succès. Forme: {monkeypox_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des données Monkeypox: {e}\")\n",
    "    monkeypox_df = None\n",
    "    \n",
    "try:\n",
    "    worldometer_df = pd.read_csv(worldometer_data_path)\n",
    "    print(f\"Données Worldometer chargées avec succès. Forme: {worldometer_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des données Worldometer: {e}\")\n",
    "    worldometer_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions de nettoyage et transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_covid_data(df):\n",
    "    \"\"\"\n",
    "    Fonction pour nettoyer les données COVID-19\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    # Copie du DataFrame pour éviter les modifications en place\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Conversion des dates en format datetime\n",
    "    if 'Date' in cleaned_df.columns:\n",
    "        cleaned_df['Date'] = pd.to_datetime(cleaned_df['Date'])\n",
    "    elif 'date' in cleaned_df.columns:\n",
    "        cleaned_df['date'] = pd.to_datetime(cleaned_df['date'])\n",
    "    \n",
    "    # Normalisation des noms de colonnes\n",
    "    cleaned_df.columns = [col.lower().replace(' ', '_') for col in cleaned_df.columns]\n",
    "    \n",
    "    # Gestion des valeurs manquantes\n",
    "    for col in cleaned_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        cleaned_df[col] = cleaned_df[col].fillna(0)\n",
    "    \n",
    "    # Normalisation des noms de pays\n",
    "    if 'country' in cleaned_df.columns:\n",
    "        # Exemple de normalisation de quelques noms de pays\n",
    "        country_mapping = {\n",
    "            'US': 'États-Unis',\n",
    "            'United States': 'États-Unis',\n",
    "            'USA': 'États-Unis',\n",
    "            'UK': 'Royaume-Uni',\n",
    "            'United Kingdom': 'Royaume-Uni',\n",
    "            'Mainland China': 'Chine',\n",
    "            'Korea, South': 'Corée du Sud',\n",
    "            'South Korea': 'Corée du Sud',\n",
    "            'Taiwan*': 'Taiwan',\n",
    "            'Iran (Islamic Republic of)': 'Iran',\n",
    "            'Hong Kong SAR': 'Hong Kong'\n",
    "        }\n",
    "        cleaned_df['country'] = cleaned_df['country'].replace(country_mapping)\n",
    "    \n",
    "    # Suppression des doublons\n",
    "    cleaned_df = cleaned_df.drop_duplicates()\n",
    "    \n",
    "    print(f\"Nettoyage des données COVID-19 terminé. Nouvelle forme: {cleaned_df.shape}\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_monkeypox_data(df):\n",
    "    \"\"\"\n",
    "    Fonction pour nettoyer les données Monkeypox\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    # Copie du DataFrame pour éviter les modifications en place\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Conversion des dates en format datetime\n",
    "    if 'Date' in cleaned_df.columns:\n",
    "        cleaned_df['Date'] = pd.to_datetime(cleaned_df['Date'])\n",
    "    elif 'date' in cleaned_df.columns:\n",
    "        cleaned_df['date'] = pd.to_datetime(cleaned_df['date'])\n",
    "    \n",
    "    # Normalisation des noms de colonnes\n",
    "    cleaned_df.columns = [col.lower().replace(' ', '_') for col in cleaned_df.columns]\n",
    "    \n",
    "    # Gestion des valeurs manquantes\n",
    "    for col in cleaned_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        cleaned_df[col] = cleaned_df[col].fillna(0)\n",
    "    \n",
    "    # Normalisation des noms de pays\n",
    "    if 'entity' in cleaned_df.columns:\n",
    "        # Renommer la colonne entity en country pour uniformité\n",
    "        cleaned_df = cleaned_df.rename(columns={'entity': 'country'})\n",
    "        \n",
    "        # Exemple de normalisation de quelques noms de pays\n",
    "        country_mapping = {\n",
    "            'United States': 'États-Unis',\n",
    "            'USA': 'États-Unis',\n",
    "            'United Kingdom': 'Royaume-Uni',\n",
    "            'South Korea': 'Corée du Sud'\n",
    "        }\n",
    "        cleaned_df['country'] = cleaned_df['country'].replace(country_mapping)\n",
    "    \n",
    "    # Suppression des doublons\n",
    "    cleaned_df = cleaned_df.drop_duplicates()\n",
    "    \n",
    "    print(f\"Nettoyage des données Monkeypox terminé. Nouvelle forme: {cleaned_df.shape}\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_worldometer_data(df):\n",
    "    \"\"\"\n",
    "    Fonction pour nettoyer les données Worldometer\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    # Copie du DataFrame pour éviter les modifications en place\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Conversion des dates en format datetime\n",
    "    if 'Date' in cleaned_df.columns:\n",
    "        cleaned_df['Date'] = pd.to_datetime(cleaned_df['Date'])\n",
    "    elif 'date' in cleaned_df.columns:\n",
    "        cleaned_df['date'] = pd.to_datetime(cleaned_df['date'])\n",
    "    \n",
    "    # Normalisation des noms de colonnes\n",
    "    cleaned_df.columns = [col.lower().replace(' ', '_') for col in cleaned_df.columns]\n",
    "    \n",
    "    # Gestion des valeurs manquantes\n",
    "    for col in cleaned_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        cleaned_df[col] = cleaned_df[col].fillna(0)\n",
    "    \n",
    "    # Normalisation des noms de pays\n",
    "    if 'country' in cleaned_df.columns:\n",
    "        # Exemple de normalisation de quelques noms de pays\n",
    "        country_mapping = {\n",
    "            'US': 'États-Unis',\n",
    "            'USA': 'États-Unis',\n",
    "            'UK': 'Royaume-Uni',\n",
    "            'S. Korea': 'Corée du Sud',\n",
    "            'UAE': 'Émirats Arabes Unis'\n",
    "        }\n",
    "        cleaned_df['country'] = cleaned_df['country'].replace(country_mapping)\n",
    "    \n",
    "    # Suppression des doublons\n",
    "    cleaned_df = cleaned_df.drop_duplicates()\n",
    "    \n",
    "    print(f\"Nettoyage des données Worldometer terminé. Nouvelle forme: {cleaned_df.shape}\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application des fonctions de nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données COVID-19\n",
    "covid_clean_df = clean_covid_data(covid_df)\n",
    "\n",
    "# Affichage des premières lignes\n",
    "if covid_clean_df is not None:\n",
    "    display(covid_clean_df.head())\n",
    "    print(\"\\nInformations sur les colonnes:\")\n",
    "    display(covid_clean_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données Monkeypox\n",
    "monkeypox_clean_df = clean_monkeypox_data(monkeypox_df)\n",
    "\n",
    "# Affichage des premières lignes\n",
    "if monkeypox_clean_df is not None:\n",
    "    display(monkeypox_clean_df.head())\n",
    "    print(\"\\nInformations sur les colonnes:\")\n",
    "    display(monkeypox_clean_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données Worldometer\n",
    "worldometer_clean_df = clean_worldometer_data(worldometer_df)\n",
    "\n",
    "# Affichage des premières lignes\n",
    "if worldometer_clean_df is not None:\n",
    "    display(worldometer_clean_df.head())\n",
    "    print(\"\\nInformations sur les colonnes:\")\n",
    "    display(worldometer_clean_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation pour la préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_confirmed_cases(covid_df, worldometer_df):\n",
    "    \"\"\"\n",
    "    Fonction pour préparer les données de cas confirmés\n",
    "    \"\"\"\n",
    "    # Initialisation d'un DataFrame vide\n",
    "    confirmed_df = pd.DataFrame()\n",
    "    \n",
    "    # Traitement des données COVID-19\n",
    "    if covid_df is not None and 'confirmed' in covid_df.columns:\n",
    "        # Sélection des colonnes pertinentes\n",
    "        covid_confirmed = covid_df[['country', 'date', 'confirmed']].copy()\n",
    "        \n",
    "        # Calcul des nouveaux cas quotidiens\n",
    "        covid_confirmed['nouveaux_cas'] = covid_confirmed.groupby('country')['confirmed'].diff().fillna(0).astype(int)\n",
    "        \n",
    "        # Renommage des colonnes\n",
    "        covid_confirmed = covid_confirmed.rename(columns={'confirmed': 'cas_cumules'})\n",
    "        \n",
    "        # Ajout d'une colonne pour identifier la pandémie\n",
    "        covid_confirmed['pandemie'] = 'COVID-19'\n",
    "        \n",
    "        # Ajout au DataFrame principal\n",
    "        confirmed_df = pd.concat([confirmed_df, covid_confirmed])\n",
    "    \n",
    "    # Traitement des données Worldometer\n",
    "    if worldometer_df is not None and 'total_cases' in worldometer_df.columns:\n",
    "        # Sélection des colonnes pertinentes\n",
    "        worldometer_confirmed = worldometer_df[['country', 'date', 'total_cases', 'new_cases']].copy()\n",
    "        \n",
    "        # Renommage des colonnes\n",
    "        worldometer_confirmed = worldometer_confirmed.rename(columns={\n",
    "            'total_cases': 'cas_cumules',\n",
    "            'new_cases': 'nouveaux_cas'\n",
    "        })\n",
    "        \n",
    "        # Ajout d'une colonne pour identifier la pandémie\n",
    "        worldometer_confirmed['pandemie'] = 'COVID-19'\n",
    "        \n",
    "        # Ajout au DataFrame principal\n",
    "        confirmed_df = pd.concat([confirmed_df, worldometer_confirmed])\n",
    "    \n",
    "    # Suppression des doublons potentiels\n",
    "    confirmed_df = confirmed_df.drop_duplicates(subset=['country', 'date'])\n",
    "    \n",
    "    # Tri par pays et date\n",
    "    confirmed_df = confirmed_df.sort_values(['country', 'date'])\n",
    "    \n",
    "    print(f\"Préparation des données de cas confirmés terminée. Forme: {confirmed_df.shape}\")\n",
    "    return confirmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_deaths(covid_df, worldometer_df):\n",
    "    \"\"\"\n",
    "    Fonction pour préparer les données de décès\n",
    "    \"\"\"\n",
    "    # Initialisation d'un DataFrame vide\n",
    "    deaths_df = pd.DataFrame()\n",
    "    \n",
    "    # Traitement des données COVID-19\n",
    "    if covid_df is not None and 'deaths' in covid_df.columns:\n",
    "        # Sélection des colonnes pertinentes\n",
    "        covid_deaths = covid_df[['country', 'date', 'deaths']].copy()\n",
    "        \n",
    "        # Calcul des nouveaux décès quotidiens\n",
    "        covid_deaths['nouveaux_deces'] = covid_deaths.groupby('country')['deaths'].diff().fillna(0).astype(int)\n",
    "        \n",
    "        # Renommage des colonnes\n",
    "        covid_deaths = covid_deaths.rename(columns={'deaths': 'deces_cumules'})\n",
    "        \n",
    "        # Ajout d'une colonne pour identifier la pandémie\n",
    "        covid_deaths['pandemie'] = 'COVID-19'\n",
    "        \n",
    "        # Ajout au DataFrame principal\n",
    "        deaths_df = pd.concat([deaths_df, covid_deaths])\n",
    "    \n",
    "    # Traitement des données Worldometer\n",
    "    if worldometer_df is not None and 'total_deaths' in worldometer_df.columns:\n",
    "        # Sélection des colonnes pertinentes\n",
    "        worldometer_deaths = worldometer_df[['country', 'date', 'total_deaths', 'new_deaths']].copy()\n",
    "        \n",
    "        # Renommage des colonnes\n",
    "        worldometer_deaths = worldometer_deaths.rename(columns={\n",
    "            'total_deaths': 'deces_cumules',\n",
    "            'new_deaths': 'nouveaux_deces'\n",
    "        })\n",
    "        \n",
    "        # Ajout d'une colonne pour identifier la pandémie\n",
    "        worldometer_deaths['pandemie'] = 'COVID-19'\n",
    "        \n",
    "        # Ajout au DataFrame principal\n",
    "        deaths_df = pd.concat([deaths_df, worldometer_deaths])\n",
    "    \n",
    "    # Suppression des doublons potentiels\n",
    "    deaths_df = deaths_df.drop_duplicates(subset=['country', 'date'])\n",
    "    \n",
    "    # Tri par pays et date\n",
    "    deaths_df = deaths_df.sort_values(['country', 'date'])\n",
    "    \n",
    "    print(f\"Préparation des données de décès terminée. Forme: {deaths_df.shape}\")\n",
    "    return deaths_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
